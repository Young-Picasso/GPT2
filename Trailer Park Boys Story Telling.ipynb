{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")\n",
    "GPT2 = TFGPT2LMHeadModel.from_pretrained(\"gpt2-large\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Andre, Matthew, and Nicky drove into the trailer park on Andre's ATV he was borrowing from Kenny. With a sputter, the engine of the ATV stalled out, again. Up the road, Mr. Lahey was looking for the roof of his car\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Andre, Matthew, and Nicky drove into the trailer park on Andre's ATV he was borrowing from Kenny. With a sputter, the engine of the ATV stalled out, again. Up the road, Mr. Lahey was looking for the roof of his car. After a bit of looking around, he discovered it had been ripped off. Mr. Lahey grabbed his ATV and began driving to a nearby convenience store for a refill.\n",
      "\n",
      "Meanwhile, Matt and Nicky, still in the trailer park, had gotten out to meet with the two children. When Matt was asked how they were, Matt answered, \"Better than you could imagine.\" Nicky continued, \"Better than me, and you better believe we are better than you.\" Matt's reply was, \"Well, we'll see about that, then.\"\n",
      "\n",
      "At this point, the family decided to leave. But Mr. Lahey continued to watch the children.\n",
      "\n",
      "Shortly after, Matt had a chance encounter with the neighbor. Mr. Lahey told him to \"fuck off\" and told him not to bother him again.\n",
      "\n",
      "Later that night, Mr. Lahey walked over to the trailer and started to bang on the window. He told the neighbor to get out of his house and leave. The neighbor refused and said, \"I can't leave without the kids.\" Mr. Lahey grabbed his gun and told him to put down the gun and walk away. The neighbor, realizing what was happening, pulled his gun out of the holster and shot the Mr. Lahey, who collapsed on the ground. The neighbor called 911.\n",
      "\n",
      "When paramedics arrived, they found the Mr. Lahey in a pool of blood. Matt was dead, and Nicky and Matt were both pronounced dead at the scene.\n",
      "\n",
      "There were no witnesses to the murder and the body of Mr. Lahey was not identified until three months later. The police, unable to identify the murderer, immediately took the case and turned it over to the Sheriff's Office.\n",
      "\n",
      "The following month, detectives began interviewing the witnesses and interviewing Mr. Lahey's relatives. They interviewed Mr. Lahey several times, but he would not talk. Eventually, he stopped answering the detectives. He was still not willing to provide a confession. Detectives were not convinced that Mr. Lahey was responsible for the murder and began to wonder if he could be guilty of other crimes.\n",
      "\n",
      "One day in\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 500\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='tf')\n",
    "sample_outputs = GPT2.generate(input_ids,\n",
    "                               do_sample = True,\n",
    "                               max_length = MAX_LEN,\n",
    "                               top_k = 50,\n",
    "                               top_p = 0.85)\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(f'{i}: {tokenizer.decode(sample_output, skip_special_tokens=True)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Andre and Mr. Lahey were drinking with Matt. It was a nice summer day in Sunnyvale Trailer Park.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Andre and Mr. Lahey were drinking with Matt. It was a nice summer day in Sunnyvale Trailer Park. Matt was drinking a couple beers. He seemed to be taking his mood down a notch.\n",
      "\n",
      "\"I just want to know why we have to do it,\" Randy said to Matt. Matt was looking at his hands in front of him, and he was shaking his head.\n",
      "\n",
      "Randy asked if he'd like to help. Matt said yes.\n",
      "\n",
      "\"What do you need to do to do it?\" Randy asked. Matt just looked at him blankly.\n",
      "\n",
      "Randy pulled out a cigarette and lit it up. He went to the back of the truck and stood in front of Matt.\n",
      "\n",
      "\"You have to stop. You have to stop, right now. I can't do it.\" Matt just stood there, not looking at Randy.\n",
      "\n",
      "Randy continued to hold out his cigarette. \"Why not?\" Matt just sat there.\n",
      "\n",
      "Randy got up and walked around the truck to Matt. Matt just sat there and did nothing. Randy walked around the truck, and eventually he walked out to Matt.\n",
      "\n",
      "\"Well, if you need help, you need to get it, right now. I'm not going to let you do it,\" Randy said.\n",
      "\n",
      "\"Randy, you've been through so much with this. I don't want to do this.\"\n",
      "\n",
      "Randy grabbed Matt's chin and pulled him to him.\n",
      "\n",
      "\"No, you can't. You have to. It's your life. You have to,\" Randy said. Matt just stared at Randy for a few moments, and then Matt just walked off.\n",
      "\n",
      "Randy went back inside the trailer.\n",
      "\n",
      "\"It's your life. Don't let someone else decide that you have to be here and that you have to stay here,\" Randy told him.\n",
      "\n",
      "Matt just sat there and did nothing.\n",
      "\n",
      "\"If you don't do it now, you'll have to do it later,\" Randy said.\n",
      "\n",
      "Matt just stared at Randy.\n",
      "\n",
      "Randy just walked away.\n",
      "\n",
      "Randy walked out of the trailer. Matt just looked at Randy and walked away. Randy was gone. Matt walked up to the truck and stood in front of it.\n",
      "\n",
      "Randy walked back into the trailer and sat in front of Matt.\n",
      "\n",
      "\"Matt, you have to stop. You have\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 500\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='tf')\n",
    "sample_outputs = GPT2.generate(input_ids,\n",
    "                               do_sample = True,\n",
    "                               max_length = MAX_LEN,\n",
    "                               top_k = 50,\n",
    "                               top_p = 0.85)\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(f'{i}: {tokenizer.decode(sample_output, skip_special_tokens=True)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py365",
   "language": "python",
   "name": "py365"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
